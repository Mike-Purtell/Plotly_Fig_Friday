{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0238ea-6930-4a02-ace7-ae0d786c43f7",
   "metadata": {},
   "source": [
    "### Plotly Figure Friday - 2024 week 47 - UFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "624361b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(us_state_abbrs) = 52\n",
      "sorted(us_state_abbrs) = ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
      "len(canada_state_abbrs) = 15\n",
      "sorted(canada_state_abbrs) = ['AB', 'BC', 'MB', 'NB', 'NF', 'NS', 'NT', 'ON', 'PE', 'PQ', 'QC', 'SA', 'SK', 'YK', 'YT']\n",
      "set.intersection(set(us_state_abbrs), set(canada_state_abbrs)) = set()\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 162\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(canada_state_abbrs)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(us_state_abbrs),\u001b[38;5;250m \u001b[39m\u001b[38;5;28mset\u001b[39m(canada_state_abbrs))\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# canada_state_abbrs = (\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m#     df\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m#     .filter(pl.col('COUNTRY_ABBR') == 'CA')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# ).sample(25)\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# df.head()\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script produces a scatter map of UFO sighting in North America, with\n",
    "informative hover that includes all of the comment fields.\n",
    "\n",
    "North America is represents over 84.8% of the data, and is expected to reach 95%\n",
    "after fixing country values of null that match US  or Canadien states. \n",
    "\n",
    "This show the values counts and percentages by country.\n",
    "┌─────────┬───────┬──────┐\n",
    "│ country ┆ count ┆ PCT  │\n",
    "│ ---     ┆ ---   ┆ ---  │\n",
    "│ str     ┆ u32   ┆ f64  │\n",
    "╞═════════╪═══════╪══════╡\n",
    "│ us      ┆ 65114 ┆ 81.1 │\n",
    "│ null    ┆ 9670  ┆ 12.0 │\n",
    "│ ca      ┆ 3000  ┆ 3.7  │\n",
    "│ gb      ┆ 1905  ┆ 2.4  │\n",
    "│ au      ┆ 538   ┆ 0.7  │\n",
    "│ de      ┆ 105   ┆ 0.1  │\n",
    "└─────────┴───────┴──────┘\n",
    "'''\n",
    "\n",
    "import plotly.express as px\n",
    "import polars as pl\n",
    "import us\n",
    "import pycountry\n",
    "\n",
    "# constants \n",
    "csv_source = 'scrubbed.csv'\n",
    "\n",
    "# functions\n",
    "def get_state_list(df, country_abbr, country_col, state_col):\n",
    "    state_abbr_list = (\n",
    "        df\n",
    "        .filter(pl.col(country_col) == country_abbr)\n",
    "        .select(pl.col(state_col, country_col))\n",
    "        .filter(pl.col(state_col).is_not_null())\n",
    "        .unique(state_col)\n",
    "        .select(pl.col(state_col))\n",
    "        .to_series().to_list()\n",
    "    )\n",
    "    return(state_abbr_list)\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "#     with us library, make dataframe of state abbreviations and names         #\n",
    "#------------------------------------------------------------------------------#\n",
    "df_us_state_names = (\n",
    "    pl.concat(  # use concat to add a row for Washington DC\n",
    "        [\n",
    "            pl.DataFrame(us.states.mapping('abbr', 'name'))\n",
    "            .transpose(include_header=True)\n",
    "            .rename({'column': 'STATE_ABBR', 'column_0': 'US_STATE'})\n",
    "            ,\n",
    "            pl.DataFrame(  # add 1-row data frame common abbr for Wash DC.\n",
    "                {\n",
    "                    'STATE_ABBR' : 'DC',\n",
    "                    'US_STATE' : 'Washington DC'\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "   \n",
    ")\n",
    "\n",
    "df_canadien_state_name = (\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "#     Read Data, minor cleanup                                                 #\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "df = (\n",
    "    pl.scan_csv(\n",
    "        csv_source,\n",
    "        ignore_errors = True,\n",
    "        try_parse_dates=True  # this converts first date from string to datetime\n",
    "    )\n",
    "    .filter(\n",
    "        pl.col('country').is_in(['us', 'ca']) \n",
    "        |\n",
    "        pl.col('country').is_null()\n",
    "    )\n",
    "    .with_columns(\n",
    "        # in the csv if formated as Month/Day/Year. After cast of \n",
    "        # the string to a date, the format is shown as Year-Month-Day\n",
    "        pl.col('date posted').str.to_date('%m/%d/%Y'),\n",
    "        pl.col('country').str.to_uppercase(),\n",
    "        pl.col('state').str.to_uppercase(),\n",
    "        pl.col('city').str.to_titlecase(),\n",
    "        # # pl.col('datetime').str.to_datetime(\"%b/%d/%Y\",strict=False)\n",
    "        # # pl.col('datetime').str.to_datetime('%b/%d/%Y %H:%M') #,strict=False)\n",
    "        # pl.col('datetime').str.to_date('%b/%d/%Y %H:%M') #,strict=False)\n",
    "    )\n",
    "    .rename({'state': 'STATE_ABBR', 'country': 'COUNTRY_ABBR'})\n",
    "    .select(pl.all().exclude('duration (hours/min)'))\n",
    "    # .with_columns(\n",
    "    #     country = pl.when(pl.col('STATE_ABBR').is_in(us_state_repairs))\n",
    "    #                 .then(pl.lit('us'))\n",
    "    #                 .otherwise('country')\n",
    "    # )\n",
    "    # .with_columns(\n",
    "    #     country = pl.when(pl.col('STATE_ABBR').is_in(canadian_state_repairs))\n",
    "    #                 .then(pl.lit('ca'))\n",
    "    #                 .otherwise('country')\n",
    "    # )\n",
    "    # .join(\n",
    "    #      df_state_names,\n",
    "    #      on='STATE_ABBR',\n",
    "    #      how='left'\n",
    "    # )\n",
    "    .collect()\n",
    ")\n",
    "# df.sample(25)\n",
    "# print(\n",
    "#     df.filter(\n",
    "#         pl.col('COUNTRY_ABBR').is_null() \n",
    "#         & \n",
    "#         pl.col('STATE_ABBR').is_not_null())\n",
    "#     .unique('STATE_ABBR')\n",
    "#     .select(pl.col('STATE_ABBR', 'COUNTRY_ABBR'))\n",
    "#     # sorted(\n",
    "#     #     list(\n",
    "#     #     df.filter(\n",
    "#     #         pl.col('COUNTRY_ABBR').is_null() \n",
    "#     #         & \n",
    "#     #         pl.col('STATE_ABBR').is_not_null())\n",
    "#     #     .unique('STATE_ABBR')\n",
    "#     #     .select(pl.col('STATE_ABBR', 'COUNTRY_ABBR'))\n",
    "#     #     )\n",
    "#     # )\n",
    "#     .sample(20)\n",
    "# )\n",
    "# #df.sample(20)\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "#     make list of each countries state names, use later to fix null values  #\n",
    "#------------------------------------------------------------------------------#\n",
    "# us_state_abbrs = sorted(list(\n",
    "#     df\n",
    "#     .filter(pl.col('COUNTRY_ABBR') == 'US')\n",
    "#     .filter(pl.col('STATE_ABBR').is_not_null())\n",
    "#     .select(pl.col('STATE_ABBR'))\n",
    "#     .unique('STATE_ABBR')\n",
    "#     # .select(pl.col('STATE_ABBR'))\n",
    "# ))\n",
    "# print(f'{list(us_state_abbrs) = }')\n",
    "# # df.head()\n",
    "\n",
    "# #------------------------------------------------------------------------------#\n",
    "# #     Fix country names with list of known state or provinces of each country  #\n",
    "# #------------------------------------------------------------------------------#\n",
    "us_state_abbrs =  get_state_list(df, 'US', 'COUNTRY_ABBR', 'STATE_ABBR')\n",
    "print(f'{len(us_state_abbrs) = }')\n",
    "print(f'{sorted(us_state_abbrs) = }')\n",
    "canada_state_abbrs =  get_state_list(df, 'CA', 'COUNTRY_ABBR', 'STATE_ABBR')\n",
    "print(f'{len(canada_state_abbrs) = }')\n",
    "print(f'{sorted(canada_state_abbrs) = }')\n",
    "\n",
    "print(f'{set.intersection(set(us_state_abbrs), set(canada_state_abbrs)) = }')\n",
    "print(1/0)\n",
    "\n",
    "# canada_state_abbrs = (\n",
    "#     df\n",
    "#     .filter(pl.col('COUNTRY_ABBR') == 'CA')\n",
    "#     .select(pl.col('STATE_ABBR', 'COUNTRY_ABBR'))\n",
    "#     .filter(pl.col('STATE_ABBR').is_null())\n",
    "#     .unique('STATE_ABBR')\n",
    "#     .select(pl.col('STATE_ABBR'))\n",
    "#     .to_series().to_list()\n",
    "# )\n",
    "# print(f'{canada_state_abbrs = }')\n",
    "\n",
    "\n",
    "# df.filter(\n",
    "#     pl.col('STATE_ABBR').is_in(canada_state_abbrs)\n",
    "#     &\n",
    "#     pl.col('COUNTRY_ABBR').is_null()\n",
    "# ).sample(25)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadd09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc507dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6, 3)\n",
      "┌─────────┬───────┬──────┐\n",
      "│ country ┆ count ┆ PCT  │\n",
      "│ ---     ┆ ---   ┆ ---  │\n",
      "│ str     ┆ u32   ┆ f64  │\n",
      "╞═════════╪═══════╪══════╡\n",
      "│ us      ┆ 65114 ┆ 81.1 │\n",
      "│ null    ┆ 9670  ┆ 12.0 │\n",
      "│ ca      ┆ 3000  ┆ 3.7  │\n",
      "│ gb      ┆ 1905  ┆ 2.4  │\n",
      "│ au      ┆ 538   ┆ 0.7  │\n",
      "│ de      ┆ 105   ┆ 0.1  │\n",
      "└─────────┴───────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     Read Data, minor cleanup                                                 #\n",
    "#------------------------------------------------------------------------------#\n",
    " \n",
    "df_value_counts = (\n",
    "    pl.scan_csv(\n",
    "        csv_source,\n",
    "        ignore_errors = True,\n",
    "        try_parse_dates=True  # this converts first date from string to datetime\n",
    "    )\n",
    "    .select(pl.col('country'))\n",
    "    .collect()\n",
    "    .to_series()\n",
    "    .value_counts()\n",
    "    .sort('count', descending=True)\n",
    "    .with_columns(PCT = (100* pl.col('count')/pl.col('count').sum()).round(1))\n",
    ")#.value_counts('country')\n",
    "print(df_value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36879de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "unable to find column \"country\"; valid columns: [\"datetime\", \"city\", \"STATE_ABBR\", \"COUNTRY_ABBR\", \"shape\", \"duration (seconds)\", \"comments\", \"date posted\", \"latitude\", \"longitude\"]\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'filter' <---\nDF [\"datetime\", \"city\", \"STATE_ABBR\", \"COUNTRY_ABBR\"]; PROJECT */10 COLUMNS; SELECTION: None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     Fix country names with list of known state or provinces of each country  #\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#------------------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m      4\u001b[0m us_state_abbrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m      5\u001b[0m     \u001b[43mdf\u001b[49m\n\u001b[1;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39munique(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATE_ABBR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATE_ABBR\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mus_state_abbrs\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mpurt\\anaconda3\\Lib\\site-packages\\polars\\dataframe\\frame.py:4768\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[1;34m(self, *predicates, **constraints)\u001b[0m\n\u001b[0;32m   4614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter\u001b[39m(\n\u001b[0;32m   4615\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4616\u001b[0m     \u001b[38;5;241m*\u001b[39mpredicates: (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4623\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconstraints: Any,\n\u001b[0;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4626\u001b[0m \u001b[38;5;124;03m    Filter the rows in the DataFrame based on one or more predicate expressions.\u001b[39;00m\n\u001b[0;32m   4627\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4766\u001b[0m \n\u001b[0;32m   4767\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredicates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mpurt\\anaconda3\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2055\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2053\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mColumnNotFoundError\u001b[0m: unable to find column \"country\"; valid columns: [\"datetime\", \"city\", \"STATE_ABBR\", \"COUNTRY_ABBR\", \"shape\", \"duration (seconds)\", \"comments\", \"date posted\", \"latitude\", \"longitude\"]\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'filter' <---\nDF [\"datetime\", \"city\", \"STATE_ABBR\", \"COUNTRY_ABBR\"]; PROJECT */10 COLUMNS; SELECTION: None"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     Fix country names with list of known state or provinces of each country  #\n",
    "#------------------------------------------------------------------------------#\n",
    "us_state_abbrs = sorted(\n",
    "    df\n",
    "    .filter(pl.col('country') == 'us')\n",
    "    .unique('STATE_ABBR')\n",
    "    .select(pl.col('STATE_ABBR'))\n",
    "    .to_series().to_list()\n",
    ")\n",
    "print(f'{us_state_abbrs = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f367083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape: (67,)\n",
      "Series: 'STATE_ABBR' [str]\n",
      "[\n",
      "\t\"WI\"\n",
      "\t\"SD\"\n",
      "\t\"RI\"\n",
      "\t\"KY\"\n",
      "\t\"TX\"\n",
      "\t…\n",
      "\t\"AZ\"\n",
      "\t\"NT\"\n",
      "\t\"MN\"\n",
      "\t\"NH\"\n",
      "\t\"TN\"\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    df\n",
    "    .with_columns(\n",
    "        country = pl.when(pl.col('STATE_ABBR').is_in(us_state_abbrs))\n",
    "                    .then(pl.lit('us'))\n",
    "                    .otherwise('country')\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    sorted(\n",
    "        list(\n",
    "        df.filter(\n",
    "            pl.col('country').is_null() \n",
    "            & \n",
    "            pl.col('STATE_ABBR').is_not_null())\n",
    "        .unique('STATE_ABBR')\n",
    "        .select(pl.col('STATE_ABBR'))\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc45e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[shape: (67,)\n",
      "Series: 'STATE_ABBR' [str]\n",
      "[\n",
      "\t\"WV\"\n",
      "\t\"AB\"\n",
      "\t\"NH\"\n",
      "\t\"CO\"\n",
      "\t\"AZ\"\n",
      "\t…\n",
      "\t\"FL\"\n",
      "\t\"MI\"\n",
      "\t\"AR\"\n",
      "\t\"MO\"\n",
      "\t\"TX\"\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sorted(\n",
    "        list(\n",
    "        df.filter(\n",
    "            pl.col('country').is_null() \n",
    "            & \n",
    "            pl.col('STATE_ABBR').is_not_null())\n",
    "        .unique('STATE_ABBR')\n",
    "        .select(pl.col('STATE_ABBR'))\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (56, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATE_ABBR</th><th>US_STATE</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;AK&quot;</td><td>&quot;Alaska&quot;</td></tr><tr><td>&quot;AL&quot;</td><td>&quot;Alabama&quot;</td></tr><tr><td>&quot;AR&quot;</td><td>&quot;Arkansas&quot;</td></tr><tr><td>&quot;AS&quot;</td><td>&quot;American Samoa&quot;</td></tr><tr><td>&quot;AZ&quot;</td><td>&quot;Arizona&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VT&quot;</td><td>&quot;Vermont&quot;</td></tr><tr><td>&quot;WA&quot;</td><td>&quot;Washington&quot;</td></tr><tr><td>&quot;WI&quot;</td><td>&quot;Wisconsin&quot;</td></tr><tr><td>&quot;WV&quot;</td><td>&quot;West Virginia&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>&quot;Wyoming&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (56, 2)\n",
       "┌────────────┬────────────────┐\n",
       "│ STATE_ABBR ┆ US_STATE       │\n",
       "│ ---        ┆ ---            │\n",
       "│ str        ┆ str            │\n",
       "╞════════════╪════════════════╡\n",
       "│ AK         ┆ Alaska         │\n",
       "│ AL         ┆ Alabama        │\n",
       "│ AR         ┆ Arkansas       │\n",
       "│ AS         ┆ American Samoa │\n",
       "│ AZ         ┆ Arizona        │\n",
       "│ …          ┆ …              │\n",
       "│ VT         ┆ Vermont        │\n",
       "│ WA         ┆ Washington     │\n",
       "│ WI         ┆ Wisconsin      │\n",
       "│ WV         ┆ West Virginia  │\n",
       "│ WY         ┆ Wyoming        │\n",
       "└────────────┴────────────────┘"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     with us library, make dataframe of state abbreviations and names         #\n",
    "#------------------------------------------------------------------------------#\n",
    "df_state_names = (\n",
    "    pl.concat(  # use concat to add a row for Washington DC\n",
    "        [\n",
    "            pl.DataFrame(us.states.mapping('abbr', 'name'))\n",
    "            .transpose(include_header=True)\n",
    "            .rename({'column': 'STATE_ABBR', 'column_0': 'US_STATE'})\n",
    "            ,\n",
    "            pl.DataFrame(  # add 1-row data frame common abbr for Wash DC.\n",
    "                {\n",
    "                    'STATE_ABBR' : 'DC',\n",
    "                    'US_STATE' : 'Washington DC'\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "   \n",
    "  \n",
    ")\n",
    "df_state_names.sort('STATE_ABBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd6e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (56, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATE_ABBR</th><th>US_STATE</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;AK&quot;</td><td>&quot;Alaska&quot;</td></tr><tr><td>&quot;AL&quot;</td><td>&quot;Alabama&quot;</td></tr><tr><td>&quot;AR&quot;</td><td>&quot;Arkansas&quot;</td></tr><tr><td>&quot;AS&quot;</td><td>&quot;American Samoa&quot;</td></tr><tr><td>&quot;AZ&quot;</td><td>&quot;Arizona&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VT&quot;</td><td>&quot;Vermont&quot;</td></tr><tr><td>&quot;WA&quot;</td><td>&quot;Washington&quot;</td></tr><tr><td>&quot;WI&quot;</td><td>&quot;Wisconsin&quot;</td></tr><tr><td>&quot;WV&quot;</td><td>&quot;West Virginia&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>&quot;Wyoming&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (56, 2)\n",
       "┌────────────┬────────────────┐\n",
       "│ STATE_ABBR ┆ US_STATE       │\n",
       "│ ---        ┆ ---            │\n",
       "│ str        ┆ str            │\n",
       "╞════════════╪════════════════╡\n",
       "│ AK         ┆ Alaska         │\n",
       "│ AL         ┆ Alabama        │\n",
       "│ AR         ┆ Arkansas       │\n",
       "│ AS         ┆ American Samoa │\n",
       "│ AZ         ┆ Arizona        │\n",
       "│ …          ┆ …              │\n",
       "│ VT         ┆ Vermont        │\n",
       "│ WA         ┆ Washington     │\n",
       "│ WI         ┆ Wisconsin      │\n",
       "│ WV         ┆ West Virginia  │\n",
       "│ WY         ┆ Wyoming        │\n",
       "└────────────┴────────────────┘"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     with us library, make dataframe of state abbreviations and names         #\n",
    "#------------------------------------------------------------------------------#\n",
    "df_state_names = (\n",
    "    pl.concat(  # use concat to add a row for Washington DC\n",
    "        [\n",
    "            pl.DataFrame(us.states.mapping('abbr', 'name'))\n",
    "            .transpose(include_header=True)\n",
    "            .rename({'column': 'STATE_ABBR', 'column_0': 'US_STATE'})\n",
    "            ,\n",
    "            pl.DataFrame(  # add 1-row data frame common abbr for Wash DC.\n",
    "                {\n",
    "                    'STATE_ABBR' : 'DC',\n",
    "                    'US_STATE' : 'Washington DC'\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "   \n",
    "  \n",
    ")\n",
    "df_state_names.sort('STATE_ABBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a17dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GB', 'DE', None, 'US', 'AU', 'CA']\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m my_country_abbrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(my_country_abbrs)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# country = pycountry.countries.get(alpha_3]2='US')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Official Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;241m.\u001b[39mofficial_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Numeric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;241m.\u001b[39mnumeric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     with pycounry library, make df to map country abbreviations to names     #\n",
    "#------------------------------------------------------------------------------#\n",
    "my_country_abbrs = list(set(df['country']))\n",
    "print(my_country_abbrs)\n",
    "print(1/0)\n",
    "# country = pycountry.countries.get(alpha_3]2='US')\n",
    "print(f\"Name: {country.name}, Official Name: {country.official_name}, Numeric: {country.numeric}\")\n",
    "for country in pycountry.countries:\n",
    "    print(f\"Name: {country.name}, Alpha-2: {country.alpha_2}, Alpha-3: {country.alpha_3}\")\n",
    "# df_country_names = (\n",
    "# )\n",
    "\n",
    "# df_state_names = (\n",
    "#     pl.concat(  # use concat to add a row for Washington DC\n",
    "#         [\n",
    "#             pl.DataFrame(us.states.mapping('abbr', 'name'))\n",
    "#             .transpose(include_header=True)\n",
    "#             .rename({'column': 'STATE_ABBR', 'column_0': 'US_STATE'})\n",
    "#             ,\n",
    "#             pl.DataFrame(  # add 1-row data frame common abbr for Wash DC.\n",
    "#                 {\n",
    "#                     'STATE_ABBR' : 'DC',\n",
    "#                     'US_STATE' : 'Washington DC'\n",
    "#                 }\n",
    "#             )\n",
    "#         ]\n",
    "#     )\n",
    "   \n",
    "  \n",
    "# )\n",
    "# df_state_names.sort('STATE_ABBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797d8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (56, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATE_ABBR</th><th>US_STATE</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;AK&quot;</td><td>&quot;Alaska&quot;</td></tr><tr><td>&quot;AL&quot;</td><td>&quot;Alabama&quot;</td></tr><tr><td>&quot;AR&quot;</td><td>&quot;Arkansas&quot;</td></tr><tr><td>&quot;AS&quot;</td><td>&quot;American Samoa&quot;</td></tr><tr><td>&quot;AZ&quot;</td><td>&quot;Arizona&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;VT&quot;</td><td>&quot;Vermont&quot;</td></tr><tr><td>&quot;WA&quot;</td><td>&quot;Washington&quot;</td></tr><tr><td>&quot;WI&quot;</td><td>&quot;Wisconsin&quot;</td></tr><tr><td>&quot;WV&quot;</td><td>&quot;West Virginia&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>&quot;Wyoming&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (56, 2)\n",
       "┌────────────┬────────────────┐\n",
       "│ STATE_ABBR ┆ US_STATE       │\n",
       "│ ---        ┆ ---            │\n",
       "│ str        ┆ str            │\n",
       "╞════════════╪════════════════╡\n",
       "│ AK         ┆ Alaska         │\n",
       "│ AL         ┆ Alabama        │\n",
       "│ AR         ┆ Arkansas       │\n",
       "│ AS         ┆ American Samoa │\n",
       "│ AZ         ┆ Arizona        │\n",
       "│ …          ┆ …              │\n",
       "│ VT         ┆ Vermont        │\n",
       "│ WA         ┆ Washington     │\n",
       "│ WI         ┆ Wisconsin      │\n",
       "│ WV         ┆ West Virginia  │\n",
       "│ WY         ┆ Wyoming        │\n",
       "└────────────┴────────────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "#     with us library, make dataframe of state abbreviations and names         #\n",
    "#------------------------------------------------------------------------------#\n",
    "df_state_names = (\n",
    "    pl.concat(  # use concat to add a row for Washington DC\n",
    "        [\n",
    "            pl.DataFrame(us.states.mapping('abbr', 'name'))\n",
    "            .transpose(include_header=True)\n",
    "            .rename({'column': 'STATE_ABBR', 'column_0': 'US_STATE'})\n",
    "            ,\n",
    "            pl.DataFrame(  # add 1-row data frame common abbr for Wash DC.\n",
    "                {\n",
    "                    'STATE_ABBR' : 'DC',\n",
    "                    'US_STATE' : 'Washington DC'\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "   \n",
    "  \n",
    ")\n",
    "df_state_names.sort('STATE_ABBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ec5fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "duration (hours/min)\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"datetime\", \"city\", \"STATE_ABBR\", \"country\"]; PROJECT */11 COLUMNS; SELECTION: None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mduration (hours/min)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mpurt\\anaconda3\\Lib\\site-packages\\polars\\dataframe\\frame.py:9021\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[1;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[0;32m   8921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[0;32m   8922\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[0;32m   8923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   8924\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   8925\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[0;32m   8926\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9019\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[0;32m   9020\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9021\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mpurt\\anaconda3\\Lib\\site-packages\\polars\\lazyframe\\frame.py:2055\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2053\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mColumnNotFoundError\u001b[0m: duration (hours/min)\n\nResolved plan until failure:\n\n\t---> FAILED HERE RESOLVING 'select' <---\nDF [\"datetime\", \"city\", \"STATE_ABBR\", \"country\"]; PROJECT */11 COLUMNS; SELECTION: None"
     ]
    }
   ],
   "source": [
    "df.select(pl.col('duration (hours/min)').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24add4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (80_332, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>datetime</th><th>city</th><th>state</th><th>country</th><th>shape</th><th>duration (seconds)</th><th>duration (hours/min)</th><th>comments</th><th>date posted</th><th>latitude</th><th>longitude</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;10/10/1949 20:30&quot;</td><td>&quot;San Marcos&quot;</td><td>&quot;TX&quot;</td><td>&quot;US&quot;</td><td>&quot;cylinder&quot;</td><td>2700</td><td>&quot;45 minutes&quot;</td><td>&quot;This event took place in early…</td><td>&quot;4/27/2004&quot;</td><td>29.883056</td><td>-97.941111</td></tr><tr><td>&quot;10/10/1949 21:00&quot;</td><td>&quot;Lackland Afb&quot;</td><td>&quot;TX&quot;</td><td>null</td><td>&quot;light&quot;</td><td>7200</td><td>&quot;1-2 hrs&quot;</td><td>&quot;1949 Lackland AFB&amp;#44 TX.  Lig…</td><td>&quot;12/16/2005&quot;</td><td>29.38421</td><td>-98.581082</td></tr><tr><td>&quot;10/10/1955 17:00&quot;</td><td>&quot;Chester (Uk/England)&quot;</td><td>null</td><td>&quot;GB&quot;</td><td>&quot;circle&quot;</td><td>20</td><td>&quot;20 seconds&quot;</td><td>&quot;Green/Orange circular disc ove…</td><td>&quot;1/21/2008&quot;</td><td>53.2</td><td>-2.916667</td></tr><tr><td>&quot;10/10/1956 21:00&quot;</td><td>&quot;Edna&quot;</td><td>&quot;TX&quot;</td><td>&quot;US&quot;</td><td>&quot;circle&quot;</td><td>20</td><td>&quot;1/2 hour&quot;</td><td>&quot;My older brother and twin sist…</td><td>&quot;1/17/2004&quot;</td><td>28.978333</td><td>-96.645833</td></tr><tr><td>&quot;10/10/1960 20:00&quot;</td><td>&quot;Kaneohe&quot;</td><td>&quot;HI&quot;</td><td>&quot;US&quot;</td><td>&quot;light&quot;</td><td>900</td><td>&quot;15 minutes&quot;</td><td>&quot;AS a Marine 1st Lt. flying an …</td><td>&quot;1/22/2004&quot;</td><td>21.418056</td><td>-157.803611</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;9/9/2013 21:15&quot;</td><td>&quot;Nashville&quot;</td><td>&quot;TN&quot;</td><td>&quot;US&quot;</td><td>&quot;light&quot;</td><td>600</td><td>&quot;10 minutes&quot;</td><td>&quot;Round from the distance/slowly…</td><td>&quot;9/30/2013&quot;</td><td>36.165833</td><td>-86.784444</td></tr><tr><td>&quot;9/9/2013 22:00&quot;</td><td>&quot;Boise&quot;</td><td>&quot;ID&quot;</td><td>&quot;US&quot;</td><td>&quot;circle&quot;</td><td>1200</td><td>&quot;20 minutes&quot;</td><td>&quot;Boise&amp;#44 ID&amp;#44 spherical&amp;#44…</td><td>&quot;9/30/2013&quot;</td><td>43.613611</td><td>-116.2025</td></tr><tr><td>&quot;9/9/2013 22:00&quot;</td><td>&quot;Napa&quot;</td><td>&quot;CA&quot;</td><td>&quot;US&quot;</td><td>&quot;other&quot;</td><td>1200</td><td>&quot;hour&quot;</td><td>&quot;Napa UFO&amp;#44&quot;</td><td>&quot;9/30/2013&quot;</td><td>38.297222</td><td>-122.284444</td></tr><tr><td>&quot;9/9/2013 22:20&quot;</td><td>&quot;Vienna&quot;</td><td>&quot;VA&quot;</td><td>&quot;US&quot;</td><td>&quot;circle&quot;</td><td>5</td><td>&quot;5 seconds&quot;</td><td>&quot;Saw a five gold lit cicular cr…</td><td>&quot;9/30/2013&quot;</td><td>38.901111</td><td>-77.265556</td></tr><tr><td>&quot;9/9/2013 23:00&quot;</td><td>&quot;Edmond&quot;</td><td>&quot;OK&quot;</td><td>&quot;US&quot;</td><td>&quot;cigar&quot;</td><td>1020</td><td>&quot;17 minutes&quot;</td><td>&quot;2 witnesses 2  miles apart&amp;#44…</td><td>&quot;9/30/2013&quot;</td><td>35.652778</td><td>-97.477778</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (80_332, 11)\n",
       "┌────────────┬────────────┬───────┬─────────┬───┬────────────┬────────────┬───────────┬────────────┐\n",
       "│ datetime   ┆ city       ┆ state ┆ country ┆ … ┆ comments   ┆ date       ┆ latitude  ┆ longitude  │\n",
       "│ ---        ┆ ---        ┆ ---   ┆ ---     ┆   ┆ ---        ┆ posted     ┆ ---       ┆ ---        │\n",
       "│ str        ┆ str        ┆ str   ┆ str     ┆   ┆ str        ┆ ---        ┆ f64       ┆ f64        │\n",
       "│            ┆            ┆       ┆         ┆   ┆            ┆ str        ┆           ┆            │\n",
       "╞════════════╪════════════╪═══════╪═════════╪═══╪════════════╪════════════╪═══════════╪════════════╡\n",
       "│ 10/10/1949 ┆ San Marcos ┆ TX    ┆ US      ┆ … ┆ This event ┆ 4/27/2004  ┆ 29.883056 ┆ -97.941111 │\n",
       "│ 20:30      ┆            ┆       ┆         ┆   ┆ took place ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ in early…  ┆            ┆           ┆            │\n",
       "│ 10/10/1949 ┆ Lackland   ┆ TX    ┆ null    ┆ … ┆ 1949       ┆ 12/16/2005 ┆ 29.38421  ┆ -98.581082 │\n",
       "│ 21:00      ┆ Afb        ┆       ┆         ┆   ┆ Lackland   ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ AFB&#44    ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ TX.  Lig…  ┆            ┆           ┆            │\n",
       "│ 10/10/1955 ┆ Chester    ┆ null  ┆ GB      ┆ … ┆ Green/Oran ┆ 1/21/2008  ┆ 53.2      ┆ -2.916667  │\n",
       "│ 17:00      ┆ (Uk/Englan ┆       ┆         ┆   ┆ ge         ┆            ┆           ┆            │\n",
       "│            ┆ d)         ┆       ┆         ┆   ┆ circular   ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ disc ove…  ┆            ┆           ┆            │\n",
       "│ 10/10/1956 ┆ Edna       ┆ TX    ┆ US      ┆ … ┆ My older   ┆ 1/17/2004  ┆ 28.978333 ┆ -96.645833 │\n",
       "│ 21:00      ┆            ┆       ┆         ┆   ┆ brother    ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ and twin   ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ sist…      ┆            ┆           ┆            │\n",
       "│ 10/10/1960 ┆ Kaneohe    ┆ HI    ┆ US      ┆ … ┆ AS a       ┆ 1/22/2004  ┆ 21.418056 ┆ -157.80361 │\n",
       "│ 20:00      ┆            ┆       ┆         ┆   ┆ Marine 1st ┆            ┆           ┆ 1          │\n",
       "│            ┆            ┆       ┆         ┆   ┆ Lt. flying ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ an …       ┆            ┆           ┆            │\n",
       "│ …          ┆ …          ┆ …     ┆ …       ┆ … ┆ …          ┆ …          ┆ …         ┆ …          │\n",
       "│ 9/9/2013   ┆ Nashville  ┆ TN    ┆ US      ┆ … ┆ Round from ┆ 9/30/2013  ┆ 36.165833 ┆ -86.784444 │\n",
       "│ 21:15      ┆            ┆       ┆         ┆   ┆ the distan ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ ce/slowly… ┆            ┆           ┆            │\n",
       "│ 9/9/2013   ┆ Boise      ┆ ID    ┆ US      ┆ … ┆ Boise&#44  ┆ 9/30/2013  ┆ 43.613611 ┆ -116.2025  │\n",
       "│ 22:00      ┆            ┆       ┆         ┆   ┆ ID&#44 sph ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ erical&#44 ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ …          ┆            ┆           ┆            │\n",
       "│ 9/9/2013   ┆ Napa       ┆ CA    ┆ US      ┆ … ┆ Napa       ┆ 9/30/2013  ┆ 38.297222 ┆ -122.28444 │\n",
       "│ 22:00      ┆            ┆       ┆         ┆   ┆ UFO&#44    ┆            ┆           ┆ 4          │\n",
       "│ 9/9/2013   ┆ Vienna     ┆ VA    ┆ US      ┆ … ┆ Saw a five ┆ 9/30/2013  ┆ 38.901111 ┆ -77.265556 │\n",
       "│ 22:20      ┆            ┆       ┆         ┆   ┆ gold lit   ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ cicular    ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ cr…        ┆            ┆           ┆            │\n",
       "│ 9/9/2013   ┆ Edmond     ┆ OK    ┆ US      ┆ … ┆ 2          ┆ 9/30/2013  ┆ 35.652778 ┆ -97.477778 │\n",
       "│ 23:00      ┆            ┆       ┆         ┆   ┆ witnesses  ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ 2  miles   ┆            ┆           ┆            │\n",
       "│            ┆            ┆       ┆         ┆   ┆ apart&#44… ┆            ┆           ┆            │\n",
       "└────────────┴────────────┴───────┴─────────┴───┴────────────┴────────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c325ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b55867",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import polars as pl\n",
    "\n",
    "# constants\n",
    "SOURCE_LOCAL = True # if True, data from csv, if False data from get git-repo\n",
    "csv_local = 'week_46_data.csv'\n",
    "\n",
    "csv_git_source = 'https://raw.githubusercontent.com/plotly/Figure-Friday/refs/'\n",
    "csv_git_source += 'heads/main/2024/week-46/PDO_wine_data_IT_FR.csv'\n",
    "\n",
    "wine_colors = {\n",
    "    'Rosé'  : '#E3AFA7',  # Rose colors vary, extracted this from a picture\n",
    "    'Red'   : '#9B2242',  # matches color named winered\n",
    "    'White' : '#E7DF99',  # white wine is not white, this is deep charconnay\n",
    "    }\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "#     initialize dataframe df_source from local file or git repo\n",
    "#------------------------------------------------------------------------------#\n",
    "if SOURCE_LOCAL:   # read cleand-up data from local directory\n",
    "    df = pl.read_csv(csv_local)       \n",
    "else:             # read source data from git_repo, and clean-up\n",
    "    df = (\n",
    "        pl.read_csv(csv_git_source)\n",
    "        .with_columns(\n",
    "            pl.col('Max_yield_hl')\n",
    "                .cast(pl.UInt16, strict=False),  # False changes na to null         \n",
    "            pl.col('Country')\n",
    "                .str.replace('FR', 'France')\n",
    "                .str.replace('IT', 'Italy')\n",
    "        )\n",
    "        .drop_nulls(subset='Max_yield_hl')\n",
    "        .select(pl.all().exclude('PDOid', 'Info'))\n",
    "        .with_columns(\n",
    "            COLOR_RGB = pl.when(pl.col('COLOR') == 'Rosé')\n",
    "                           .then(pl.lit('#FF0080'))\n",
    "        )\n",
    "    )\n",
    "    df.write_csv(csv_local)\n",
    "    df.head()\n",
    "\n",
    "fig = px.violin(\n",
    "    df,\n",
    "    x='Color',\n",
    "    y='Max_yield_hl',\n",
    "    facet_col='COUNTRY',\n",
    "    title = (\n",
    "        'Maximum permitted wine yield (hectoliters per hectare) in France and Italy'\n",
    "        '<a href=\"https://en.wikipedia.org/wiki/Yield_(wine)\" ' + \n",
    "        'style=\"color:yellow;\"> Wikipedia LINK</a>'\n",
    "    ),\n",
    "    color='Color', \n",
    "    color_discrete_map=wine_colors,\n",
    "    template='plotly_dark',\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(size=16), \n",
    "    showlegend=False,\n",
    "    # xaxis_title=dict(text='Date', font=dict(size=16, color='#FFFFFF')),\n",
    "    yaxis_title=dict(text=''),\n",
    ")\n",
    "\n",
    "# next line changes facet labels from COUNTRY=xyz, to just show xyz\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.replace(\"COUNTRY=\", \"\")))\n",
    "\n",
    "# # this syntax is specific to the faceted plot\n",
    "fig.update_xaxes(title='')\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('Wines.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
